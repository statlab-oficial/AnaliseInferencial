% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

% pacotes úteis
\usepackage{amsmath}
\usepackage{array}      % para o \begin{array} usado pelo \stackunder
% \usepackage{stackengine} % (opcional) se quiser usar a versão do pacote \stackunder

% suas macros
\newcommand{\tn}{\mbox{\boldmath $\theta$} }
\newcommand{\sn}{\mbox{\boldmath $\sigma$} }
\newcommand{\On}{\mbox{\boldmath $\Omega$} }
\newcommand{\Dn}{\mbox{\boldmath $\Delta$} }
\newcommand{\In}{\mbox{\textbf{I}} }
\newcommand{\yn}{\mbox{\textbf{y}} }
\newcommand{\Vn}{\mbox{\textbf{V}} }
\newcommand{\mn}{\mbox{\boldmath $\mu$} }
\newcommand{\Fn}{\mbox{\boldmath $\Phi$} }
\newcommand{\Pn}{\mbox{\boldmath $\Pi$} }

\newenvironment{Dproof}[1][DProof]{\textbf{#1.} }{\ \rule{0.2cm}{0.2cm}} 
\newcommand{\stackunder}[2]{ \renewcommand{\arraystretch}{0.2} 
\displaystyle \begin{array}[t]{c}  {#1}\\_{#2}\end{array} 
\renewcommand{\arraystretch}{1}} 
\newcommand{\vect}[1]{\!\!\!\stackunder{#1}{\sim}\!\!\!}
\renewcommand{\Re}{I \! \! R}
\newcommand{\real}{\mbox{$I\!\!R$}}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\va}{$X_1,\,X_2,\,\dots,\,X_n$}
\newcommand{\vam}{$x_1,\,x_2\,\ldots,\,x_n$}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Índice}
\else
  \newcommand\contentsname{Índice}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Lista de Figuras}
\else
  \newcommand\listfigurename{Lista de Figuras}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Lista de Tabelas}
\else
  \newcommand\listtablename{Lista de Tabelas}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figura}
\else
  \newcommand\figurename{Figura}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Tabela}
\else
  \newcommand\tablename{Tabela}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listagem}
\newcommand*\listoflistings{\listof{codelisting}{Lista de Listagens}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{brazilian}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Análise Inferencial},
  pdfauthor={Manoel Santos-Neto},
  pdflang={pt-BR},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Análise Inferencial}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Departamento de Estatística e Matemática Aplicada}
\author{Manoel Santos-Neto}
\date{2026-02-08}

\begin{document}
\maketitle

\renewcommand*\contentsname{Índice}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\chapter*{Prefácio}\label{prefuxe1cio}
\addcontentsline{toc}{chapter}{Prefácio}

\markboth{Prefácio}{Prefácio}

\bookmarksetup{startatroot}

\chapter{IDENTIFICAÇÃO DA
DISCIPLINA}\label{identificauxe7uxe3o-da-disciplina}

\begin{itemize}
\item
  Curso: Bacharelado em Ciência de Dados
\item
  Disciplina: Análise Inferencial
\item
  Carga Horária: 96 horas
\item
  Créditos: 6
\item
  Regime: Semestral
\item
  Pré-requisitos: Probabilidade e Estatística Descritiva (ou
  equivalente)
\item
  Período Letivo: 2026.1
\item
  Professor(a): Dr.~Manoel Santos-Neto
\end{itemize}

\bookmarksetup{startatroot}

\chapter{EMENTA}\label{ementa}

Conceitos de população e amostra; parâmetros, estatísticas, estimadores
e suas propriedades; distribuições amostrais; métodos de estimação
pontual: método dos momentos, máxima verossimilhança e mínimos
quadrados; estimação intervalar; testes de hipóteses; testes de
homogeneidade e independência.

\bookmarksetup{startatroot}

\chapter{OBJETIVO GERAL}\label{objetivo-geral}

Apresentar os fundamentos da inferência estatística, capacitando o
estudante a formular, analisar e interpretar problemas inferenciais em
contextos de Ciência de Dados, com ênfase na quantificação da incerteza,
validação de modelos e capacidade de generalização.

\bookmarksetup{startatroot}

\chapter{OBJETIVOS ESPECÍFICOS}\label{objetivos-especuxedficos}

Ao final da disciplina, o estudante deverá ser capaz de:

\begin{itemize}
\item
  compreender a diferença entre população, amostra, parâmetro e
  estatística;
\item
  interpretar estatísticas como variáveis aleatórias;
\item
  compreender e utilizar distribuições amostrais;
\item
  aplicar métodos de estimação pontual e intervalar;
\item
  formular e testar hipóteses estatísticas de forma adequada;
\item
  interpretar corretamente p-valores, intervalos de confiança e decisões
  inferenciais;
\item
  relacionar conceitos de inferência estatística com validação cruzada,
  generalização e avaliação de modelos de Machine Learning;
\item
  analisar criticamente resultados estatísticos obtidos a partir de
  dados reais.
\end{itemize}

\bookmarksetup{startatroot}

\chapter{CONTEÚDO PROGRAMÁTICO}\label{conteuxfado-programuxe1tico}

\section*{Unidade I -- Fundamentos da Inferência
Estatística}\label{unidade-i-fundamentos-da-inferuxeancia-estatuxedstica}
\addcontentsline{toc}{section}{Unidade I -- Fundamentos da Inferência
Estatística}

\markright{Unidade I -- Fundamentos da Inferência Estatística}

\begin{itemize}
\item
  População e amostra
\item
  Processo gerador de dados
\item
  Parâmetros e estatísticas
\item
  Variabilidade amostral
\end{itemize}

\section*{Unidade II -- Distribuições
Amostrais}\label{unidade-ii-distribuiuxe7uxf5es-amostrais}
\addcontentsline{toc}{section}{Unidade II -- Distribuições Amostrais}

\markright{Unidade II -- Distribuições Amostrais}

\begin{itemize}
\item
  Estatísticas como variáveis aleatórias
\item
  Distribuição amostral da média e da proporção
\item
  Lei dos Grandes Números
\item
  Teorema Central do Limite
\end{itemize}

\section*{Unidade III -- Estimação
Pontual}\label{unidade-iii-estimauxe7uxe3o-pontual}
\addcontentsline{toc}{section}{Unidade III -- Estimação Pontual}

\markright{Unidade III -- Estimação Pontual}

\begin{itemize}
\item
  Estimadores e estimativas
\item
  Propriedades dos estimadores (viés, variância, MSE, consistência)
\item
  Método dos momentos
\item
  Máxima verossimilhança
\item
  Mínimos quadrados
\end{itemize}

\section*{Unidade IV -- Estimação
Intervalar}\label{unidade-iv-estimauxe7uxe3o-intervalar}
\addcontentsline{toc}{section}{Unidade IV -- Estimação Intervalar}

\markright{Unidade IV -- Estimação Intervalar}

\begin{itemize}
\item
  Intervalos de confiança
\item
  Interpretação correta
\item
  Intervalos baseados em aproximações assintóticas
\item
  Bootstrap
\end{itemize}

\section*{Unidade V -- Testes de
Hipóteses}\label{unidade-v-testes-de-hipuxf3teses}
\addcontentsline{toc}{section}{Unidade V -- Testes de Hipóteses}

\markright{Unidade V -- Testes de Hipóteses}

\begin{itemize}
\item
  Formulação de hipóteses
\item
  Estatísticas de teste
\item
  p-valor
\item
  Erros tipo I e tipo II
\item
  Poder do teste
\end{itemize}

\section*{Unidade VI -- Testes de Homogeneidade e
Independência}\label{unidade-vi-testes-de-homogeneidade-e-independuxeancia}
\addcontentsline{toc}{section}{Unidade VI -- Testes de Homogeneidade e
Independência}

\markright{Unidade VI -- Testes de Homogeneidade e Independência}

\begin{itemize}
\item
  Testes qui-quadrado
\item
  Tabelas de contingência
\item
  Associação entre variáveis categóricas
\end{itemize}

\section*{Unidade VII -- Inferência Estatística e Ciência de
Dados}\label{unidade-vii-inferuxeancia-estatuxedstica-e-ciuxeancia-de-dados}
\addcontentsline{toc}{section}{Unidade VII -- Inferência Estatística e
Ciência de Dados}

\markright{Unidade VII -- Inferência Estatística e Ciência de Dados}

\begin{itemize}
\item
  Relação entre inferência estatística e Machine Learning
\item
  Validação cruzada
\item
  Generalização e overfitting
\item
  Interpretação inferencial de modelos preditivos
\end{itemize}

\bookmarksetup{startatroot}

\chapter{METODOLOGIA}\label{metodologia}

A disciplina será desenvolvida por meio de aulas expositivo-dialogadas,
articuladas com atividades práticas computacionais. O conteúdo teórico
será constantemente ilustrado por simulações e análises de dados reais,
utilizando ferramentas computacionais (R ou Python).

Serão propostas listas semanais obrigatórias, com foco em
experimentação, interpretação estatística e conexão com problemas de
Machine Learning, validação de modelos e generalização. O uso de
simulação, reamostragem e análise empírica será empregado como
ferramenta pedagógica para construção da intuição inferencial.

\bookmarksetup{startatroot}

\chapter{AVALIAÇÃO}\label{avaliauxe7uxe3o}

A avaliação será contínua e composta por:

\begin{itemize}
\item
  Listas semanais obrigatórias (atividades computacionais com
  interpretação estatística): 50\%
\item
  Projeto final inferencial aplicado a dados reais: 30\%
\item
  Avaliação conceitual individual (prova ou atividade equivalente): 20\%
\end{itemize}

A aprovação na disciplina seguirá os critérios estabelecidos pelas
normas vigentes da UFC.

\bookmarksetup{startatroot}

\chapter{CRITÉRIOS DE AVALIAÇÃO}\label{crituxe9rios-de-avaliauxe7uxe3o}

Serão considerados nos trabalhos e atividades:

\begin{itemize}
\item
  correção conceitual;
\item
  adequação metodológica;
\item
  clareza na formulação do problema inferencial;
\item
  interpretação estatística correta dos resultados;
\item
  organização, clareza e reprodutibilidade das análises.
\end{itemize}

\bookmarksetup{startatroot}

\chapter{BIBLIOGRAFIA BÁSICA}\label{bibliografia-buxe1sica}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Bussab, W. O.; Morettin, P. A. Estatística Básica. 6ª ed.~São Paulo:
  Saraiva, 2010.
\item
  Casella, G.; Berger, R. L. Statistical Inference. 2nd ed.~New York:
  Duxbury Press, 2001.
\item
  Casella, G.; Berger, R. L. Inferência Estatística. Tradução da 2ª
  edição. São Paulo: Cengage Learning, 2011.
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{BIBLIOGRAFIA COMPLEMENTAR}\label{bibliografia-complementar}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Devore, J. L. Probabilidade e Estatística para Engenharia e Ciências.
  São Paulo: Thomson, 2006.
\item
  Mood, A. M.; Graybill, F.; Boes, D. C. Introduction to the Theory of
  Statistics. 3rd ed.~New York: McGraw-Hill, 1974.
\item
  Bolfarine, H.; Sandoval, M. C. Introdução à Inferência Estatística.
  Rio de Janeiro: SBM, 2001.
\item
  Bickel, P. J.; Doksum, K. A. Mathematical Statistics. Vol. I, 2nd
  ed.~New Jersey: Prentice Hall, 2007.
\item
  Dudewicz, E. J.; Mishra, S. N. Modern Mathematical Statistics. New
  York: John Wiley, 1988.
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{OBSERVAÇÕES FINAIS}\label{observauxe7uxf5es-finais}

A disciplina enfatiza a inferência estatística como base conceitual da
Ciência de Dados, destacando a importância da quantificação da
incerteza, da validação de modelos e da interpretação crítica dos
resultados em contextos reais.

\bookmarksetup{startatroot}

\chapter{Fundamentos da Inferência
Estatística}\label{fundamentos-da-inferuxeancia-estatuxedstica}

Neste capítulo, iniciamos a primeira parte sobre inferência estatística
aprendendo um pouco sobre amostragem. Os conceitos por trás da amostram
são a base para intervalos de confiança e testes de hipóteses, por
exemplo. Além disso, veremos que ferramentas já aprendidas durante o
curso de Ciência de Dados, em particular visualização de dados e
manipulação (organização) de dados, são importantes no desenvolvimento
do seu entendimento. Esperamos que os conceitos apresentados ao longo
deste texto se articulam e se acumulam, culminando na capacidade de
``contar sua história com dados''.

\section{Pacote Necessários}\label{pacote-necessuxe1rios}

Neste capítulo iremos utilizar os pacotes \texttt{R} \texttt{tidyverse}
e \texttt{moderndive}. Por exemplo, para instalar o pacote basta usar
\texttt{install.packages("tidyverse")} e podemos carregar o pacote por
meio do comando \texttt{library(tidyverse)}. São carregados, de uma só
vez, os seguinte pacotes amplamente utilizados em ciência de dados:

\begin{itemize}
\item
  \texttt{ggplot2} para visualização de dados;
\item
  \texttt{dplyr} para manipulação de dados;
\item
  \texttt{tidyr} para converter dados para o formato ``tidy'';
\item
  \texttt{readr} para importar dados de planilhas para o \texttt{R},
\end{itemize}

além dos pacotes mais avançados \texttt{purrr}, \texttt{tibble},
\texttt{stringr} e \texttt{forcats}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --
v dplyr     1.1.4     v readr     2.1.5
v forcats   1.0.0     v stringr   1.5.2
v ggplot2   4.0.0     v tibble    3.3.0
v lubridate 1.9.3     v tidyr     1.3.1
v purrr     1.1.0     
-- Conflicts ------------------------------------------ tidyverse_conflicts() --
x dplyr::filter() masks stats::filter()
x dplyr::lag()    masks stats::lag()
i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(moderndive)}
\end{Highlighting}
\end{Shaded}

\section{Experimento em Sala de Aula}\label{experimento-em-sala-de-aula}

Iremos realizar o seguinte experimento em sala de aula:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Organização
\end{enumerate}

\begin{itemize}
\item
  A turma é dividida em grupos independentes (por exemplo, 33 grupos).
\item
  Cada grupo realiza uma única amostragem.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Protocolo experimental (por grupo)
\end{enumerate}

\begin{itemize}
\item
  A urna é misturada cuidadosamente, garantindo aleatoriedade.
\item
  O grupo retira uma amostra de tamanho fixo \(n\) (por exemplo,
  \(n=50\)) sem reposição durante a retirada.
\item
  As bolas retiradas são observadas e classificadas por cor.
\item
  O grupo registra:

  \begin{itemize}
  \tightlist
  \item
    \(R:\) o número de bolas vermelhas na amostra;
  \item
    \(\hat{p} = R/n:\) proporção amostral de bolas vermelhas.
  \end{itemize}
\item
  Todas as bolas são devolvidas à urna.
\item
  A urna é novamente misturada antes da próxima amostragem.
\end{itemize}

\textbf{Cada grupo deve atuar de forma independente, sem acesso aos
resultados dos demais.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Coleta e organização dos dados
\end{enumerate}

\begin{itemize}
\item
  Cada grupo fornece sua estimativa de \(\hat{p}\).
\item
  O conjunto de estimativas é reunido em uma tabela ou planilha.
\item
  A proporções são representadas graficamente por meio de um histograma.
\end{itemize}

\textbf{Esse histograma representa a distribuição amostral da proporção
para uma tamanho de amostra fixo \(n\).}

\subsection*{Verificação de
aprendizagem}\label{verificauxe7uxe3o-de-aprendizagem}
\addcontentsline{toc}{subsection}{Verificação de aprendizagem}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Por que foi importante misturar a tigela antes de retirarmos as bolas?
\item
  Por que os 33 grupos de amigos não obtiveram todos o mesmo número de
  bolas vermelhas entre as 50 retiradas e, consequentemente, proporções
  diferentes de bolas vermelhas?
\end{enumerate}

\section{Experimento Virtual}\label{experimento-virtual}

No pacote \texttt{moderndive} existe um \emph{data frame} chamado
\texttt{bowl}. As linhas de \texttt{bowl} correspondem exatamente ao
conteúdo da urna real apresentada em sala de aula.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bowl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 2,400 x 2
   ball_ID color
     <int> <chr>
 1       1 white
 2       2 white
 3       3 white
 4       4 red  
 5       5 white
 6       6 white
 7       7 red  
 8       8 white
 9       9 red  
10      10 white
# i 2,390 more rows
\end{verbatim}

Observe que \texttt{bowl} possui 2400 linhas, o que nos indica que a
urna contém 2400 bolas de mesmo tamanho. A primeira variável,
\texttt{ball\_ID}, é usada como uma variável de identificação, conforme
discutido em sala de aula, nenhuma das bolas da urna real possui números
marcados. A segunda variável, \texttt{color}, indica se uma determinada
bola virtual é \textbf{vermelha} ou \textbf{branca}. Visualize o
conteúdo de \texttt{bowl} no \textbf{visualizador de dados do RStudio} e
percorra as linhas para se convencer de que \texttt{bowl} é, de fato, um
\textbf{análogo virtual} da urna real apresentada em sala.

Agora precisamos de um \textbf{análogo virtual da pá} para gerar
\textbf{amostras virtuais de 50 bolas}. Para isso, vamos utilizar a
função \texttt{rep\_sample\_n()}, incluída no pacote
\texttt{moderndive}. Essa função permite realizar \textbf{amostragens
repetidas (ou replicadas)} de tamanho (n).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pa\_virtual }\OtherTok{\textless{}{-}}\NormalTok{ bowl }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{rep\_sample\_n}\NormalTok{(}\AttributeTok{size =} \DecValTok{50}\NormalTok{)}

\NormalTok{pa\_virtual}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 50 x 3
# Groups:   replicate [1]
   replicate ball_ID color
       <int>   <int> <chr>
 1         1     401 white
 2         1     744 red  
 3         1     174 red  
 4         1     781 white
 5         1    1745 red  
 6         1     309 white
 7         1    2281 white
 8         1     396 red  
 9         1    1322 white
10         1    1967 white
# i 40 more rows
\end{verbatim}

A variável \texttt{ball\_ID} identifica quais das 2400 bolas do objeto
\texttt{bowl} foram incluídas na nossa amostra de 50 bolas, enquanto
\texttt{color} indica a cor de cada bola. No entanto, o que indica a
variável \texttt{replicate}?

No caso de \texttt{pa\_virtual}, a variável \texttt{replicate} é igual a
1 em todas as 50 linhas. Isso nos informa que essas 50 linhas
correspondem à nossa primeira amostra. Veremos em breve que, quando
realizarmos 33 amostragens virtuais, a variável \texttt{replicate}
assumirá valores entre 1 e 33.

Vamos agora calcular a \textbf{proporção de bolas vermelhas} em nossa
amostra virtual utilizando os verbos de manipulação de dados do
\texttt{dplyr}. Primeiro, para cada uma das 50 bolas amostradas, vamos
identificar se ela é vermelha ou não, utilizando um teste de igualdade
com \texttt{==}. Em seguida, criaremos uma nova variável booleana
\texttt{is\_red} usando a função \texttt{mutate()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pa\_virtual }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{is\_red =}\NormalTok{ (color }\SpecialCharTok{==} \StringTok{"red"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 50 x 4
# Groups:   replicate [1]
   replicate ball_ID color is_red
       <int>   <int> <chr> <lgl> 
 1         1     401 white FALSE 
 2         1     744 red   TRUE  
 3         1     174 red   TRUE  
 4         1     781 white FALSE 
 5         1    1745 red   TRUE  
 6         1     309 white FALSE 
 7         1    2281 white FALSE 
 8         1     396 red   TRUE  
 9         1    1322 white FALSE 
10         1    1967 white FALSE 
# i 40 more rows
\end{verbatim}

Observe que, para cada linha em que \texttt{color\ ==\ "red"}, é
retornado o valor lógico (booleano) \texttt{TRUE}, e para cada linha em
que \texttt{color} não é igual a \texttt{"red"}, é retornado o valor
lógico \texttt{FALSE}.

Em seguida, vamos calcular o número de bolas vermelhas, dentre as 50,
utilizando a função \texttt{summarize()}. Note que \texttt{summarize()}
recebe um \emph{data frame} com várias linhas e retorna um \emph{data
frame} com \textbf{uma única linha}, contendo estatísticas-resumo, como
\texttt{mean()} ou \texttt{median()}. Neste caso, utilizaremos a função
\texttt{sum()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pa\_virtual }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{is\_red =}\NormalTok{ (color }\SpecialCharTok{==} \StringTok{"red"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{summarize}\NormalTok{(}\AttributeTok{num\_red =} \FunctionTok{sum}\NormalTok{(is\_red))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 2
  replicate num_red
      <int>   <int>
1         1      17
\end{verbatim}

Por que isso funciona? Porque o \texttt{R} trata \texttt{TRUE} como o
número 1 e \texttt{FALSE} como o número 0. Assim, somar valores
\texttt{TRUE} e \texttt{FALSE} é equivalente a somar 1's e 0's. Ao
final, essa operação conta o número de bolas para as quais a variável
color é igual a ``red''. No nosso caso, XX das 50 bolas eram vermelhas.
No entanto, você pode ter obtido um número diferente de bolas vermelhas
devido ao caráter aleatório da amostragem virtual.

Por fim, vamos calcular a proporção das 50 bolas amostradas que são
vermelhas, dividindo num\_red por 50:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pa\_virtual }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{is\_red =}\NormalTok{ color }\SpecialCharTok{==} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{summarize}\NormalTok{(}\AttributeTok{num\_red =} \FunctionTok{sum}\NormalTok{(is\_red)) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{prop\_red =}\NormalTok{ num\_red }\SpecialCharTok{/} \DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 3
  replicate num_red prop_red
      <int>   <int>    <dbl>
1         1      17     0.34
\end{verbatim}

Em outras palavras, XX das bolas dessa amostra virtual eram vermelhas.
Vamos tornar esse código um pouco mais \textbf{compacto e conciso},
combinando as etapas de \texttt{mutate()} e \texttt{summarize()} da
seguinte forma:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pa\_virtual }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{summarize}\NormalTok{(}\AttributeTok{num\_red =} \FunctionTok{sum}\NormalTok{(color }\SpecialCharTok{==} \StringTok{"red"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{prop\_red =}\NormalTok{ num\_red }\SpecialCharTok{/} \DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 3
  replicate num_red prop_red
      <int>   <int>    <dbl>
1         1      17     0.34
\end{verbatim}

Ótimo! XX das 50 bolas de virtual\_shovel eram vermelhas! Assim, com
base nessa amostra específica de 50 bolas, nossa estimativa da proporção
de bolas vermelhas na urna é XX. Porém, lembre-se da atividade de
amostragem realizada em sala de auma: se repetirmos essa amostragem, não
necessariamente obteremos novamente o valor de XX. É provável que haja
alguma variação. De fato, nossos 33 grupos de amigos calcularam 33
proporções desse tipo, cuja distribuição visualizamos em sala de aula, e
vimos que essas estimativas variaram.

Vamos agora realizar o \textbf{análogo virtual} de ter 33 grupos de
estudantes usando a pá de amostragem!

Lembre-se de que, no exercício de amostragem realizada em sala de aula,
tivemos \textbf{33 grupos de estudantes}, cada um utilizando a pá, o que
resultou em \textbf{33 amostras de tamanho 50}. Em seguida, usamos essas
33 amostras para calcular \textbf{33 proporções}. Em outras palavras,
\textbf{repetimos/replicamos o uso da pá 33 vezes}.

Podemos realizar essa amostragem repetida/replicada de forma virtual
utilizando novamente a função \texttt{rep\_sample\_n()}, mas agora
adicionando o argumento \texttt{reps\ =\ 33}. Isso indica ao R que
desejamos repetir a amostragem 33 vezes.

Vamos salvar esses resultados em um \texttt{data\ frame} chamado
\texttt{virtual\_samples}. Embora apresentemos a seguir uma prévia das
primeiras 10 linhas de \texttt{virtual\_samples}, recomendamos
fortemente que você explore todo o seu conteúdo utilizando o
visualizador de planilhas do RStudio, executando o comando
\texttt{View(virtual\_samples)}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{amostra\_virtual }\OtherTok{\textless{}{-}}\NormalTok{ bowl }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{rep\_sample\_n}\NormalTok{(}\AttributeTok{size =} \DecValTok{50}\NormalTok{, }\AttributeTok{reps =} \DecValTok{33}\NormalTok{)}

\NormalTok{amostra\_virtual}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1,650 x 3
# Groups:   replicate [33]
   replicate ball_ID color
       <int>   <int> <chr>
 1         1    1352 white
 2         1    2269 red  
 3         1    2059 white
 4         1     173 white
 5         1    1539 white
 6         1      25 red  
 7         1    1334 white
 8         1    1392 white
 9         1    1168 red  
10         1    1145 red  
# i 1,640 more rows
\end{verbatim}

Observe, no visualizador de planilhas, que as primeiras 50 linhas da
variável \texttt{replicate} são iguais a 1, enquanto as 50 linhas
seguintes de \texttt{replicate} são iguais a 2. Isso nos indica que as
primeiras 50 linhas correspondem à primeira amostra de 50 bolas,
enquanto as próximas 50 linhas correspondem à segunda amostra de 50
bolas. Esse padrão se repete para todas as 33 replicações
(\texttt{reps\ =\ 33}) e, portanto, o \texttt{data\ frame}
\texttt{amostra\_virtual} possui (33 \cdot 50 = 1650) linhas.

Vamos agora usar \texttt{amostra\_virtual} para calcular as 33
proporções de bolas vermelhas resultantes. Utilizaremos os mesmos verbos
do \texttt{dplyr} de antes, mas agora com um \texttt{group\_by()}
adicional na variável \texttt{replicate}. Ao definir previamente a
variável de agrupamento como \emph{metadado} antes de aplicar
\texttt{summarize()}, obteremos 33 proporções diferentes de bolas
vermelhas. A seguir, exibimos uma prévia das primeiras 10 das 33 linhas
resultantes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{virtual\_prop\_red }\OtherTok{\textless{}{-}}\NormalTok{ amostra\_virtual }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{group\_by}\NormalTok{(replicate) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{summarize}\NormalTok{(}\AttributeTok{red =} \FunctionTok{sum}\NormalTok{(color }\SpecialCharTok{==} \StringTok{"red"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{prop\_red =}\NormalTok{ red }\SpecialCharTok{/} \DecValTok{50}\NormalTok{)}

\NormalTok{virtual\_prop\_red}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 33 x 3
   replicate   red prop_red
       <int> <int>    <dbl>
 1         1    20     0.4 
 2         2    17     0.34
 3         3    14     0.28
 4         4    22     0.44
 5         5    18     0.36
 6         6    22     0.44
 7         7    17     0.34
 8         8    14     0.28
 9         9    17     0.34
10        10    14     0.28
# i 23 more rows
\end{verbatim}

Assim como ocorreu com as 33 amostras coletadas em sala de aula, há
variação nas 33 proporções de bolas vermelhas obtidas virtualmente.
Vamos visualizar essa variação por meio de um histograma. Note que
também adicionamos os argumentos \texttt{binwidth\ =\ 0.05} e
\texttt{boundary\ =\ 0.4}.

Lembre-se de que definir \texttt{boundary\ =\ 0.4} garante um esquema de
classes em que um dos limites dos intervalos esteja em 0,4. Como o
\texttt{binwidth\ =\ 0.05} também foi especificado, isso criará
intervalos com limites em \textbf{0,30, 0,35, 0,40, 0,45, 0,50}, entre
outros.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(virtual\_prop\_red, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ prop\_red)) }\SpecialCharTok{+}
\FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{boundary =} \FloatTok{0.4}\NormalTok{, }\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
\FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Proportion of 50 balls that were red"}\NormalTok{,}
\AttributeTok{title =} \StringTok{"Distribution of 33 proportions red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{unidade1_files/figure-pdf/unnamed-chunk-10-1.pdf}

Observe que, ocasionalmente, obtivemos proporções de bolas vermelhas
inferiores a 30\%. Por outro lado, em alguns casos, obtivemos proporções
superiores a 45\%. No entanto, as proporções que ocorreram com maior
frequência ficaram entre 35\% e 40\% (em \textbf{11 das 33 amostras}).
Por que temos essas diferenças nas proporções de bolas vermelhas?
\textbf{Por causa da variação amostral}.

\subsection*{Verificação de
aprendizagem}\label{verificauxe7uxe3o-de-aprendizagem-1}
\addcontentsline{toc}{subsection}{Verificação de aprendizagem}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Por que não foi possível estudar os efeitos da variação amostral
  quando utilizamos a pá virtual apenas uma vez? Por que foi necessário
  coletar \textbf{mais de uma amostra virtual} (no nosso caso,
  \textbf{33 amostras virtuais})?
\end{enumerate}

\subsection*{Lista Semanal
Obrigatória}\label{lista-semanal-obrigatuxf3ria}
\addcontentsline{toc}{subsection}{Lista Semanal Obrigatória}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Agora suponha que queiramos estudar os efeitos da variação amostral
  não para 33 amostras, mas para um número maior, digamos 1000 amostras.
  Vamos novamente utilizar a função \texttt{rep\_sample\_n()}, com o
  tamanho da amostra definido como 50, mas agora com o número de
  repetições \texttt{reps} definido como 1000.
\item
  Temos 1000 réplicas de \texttt{prop\_red}, a proporção de bolas
  vermelhas em amostras de 50 bolas. Utilizando o mesmo código de antes,
  vamos agora visualizar a distribuição dessas 1000 réplicas de
  \texttt{prop\_red} por meio de um histograma.
\item
  Observando o histograma produzido no item 2), você diria que amostrar
  50 bolas em que 30\% são vermelhas é provável ou improvável? E quanto
  a amostrar 50 bolas em que 10\% são vermelhas?
\end{enumerate}

\section{Conceitos Importantes}\label{conceitos-importantes}

A seguir, apresentamos uma lista de termos e notação matemática
relacionados à amostragem.

Primeiramente, uma \textbf{população} é um conjunto de indivíduos ou
observações de interesse. Isso também é comumente denominado
\textbf{população de estudo}. Denotamos matematicamente o tamanho da
população utilizando a letra maiúscula \(N\). Na nossa atividade de
amostragem, a \textbf{população (de estudo)} é o conjunto de
\(N = 2400\) bolas vermelhas e brancas, todas de mesmo tamanho, contidas
na urna.

\bookmarksetup{startatroot}

\chapter{Distribuições Amostrais}\label{distribuiuxe7uxf5es-amostrais}

\bookmarksetup{startatroot}

\chapter{Estimação Pontual}\label{estimauxe7uxe3o-pontual}

\section{Estimador de Momentos}\label{estimador-de-momentos}

Este método de estimação é um dos métodos mais antigos de estimação. Ele
é utilizado desde o século XVIII. A ideia é bem simples. Vamos
inicialmente definir para o caso uniparamétrico:

Seja \(X\) uma variável aleatória com a seguinte f.d.p. ou f.p. ,
\(f(x\;|\theta)\), suporte \(A\) , espaço paramétrico \(\Theta\) e
\(E_{\theta}(X^r)<\infty,\; r=1,2,\dots\).

Seja a amostra aleatória \(X_1,X_2,\ldots,X_n\) de \(X\) . Vamos igualar
o primeiro populacional ao primeiro momento amostral, isto é,

\[E_{\theta}(X)= \bar{X}.\]

Vamos fazer alguns exemplos para fixar o conceito calculando também sua
variância amostral.

\textbf{Exemplo 1:} Considere \(X \sim U( (0,\theta)\) com

\[E_{\theta}(X)=\frac{\theta}{2}\quad \text{e} \quad V(X)=\frac{\theta^2}{12}.\]

Assim,

\[E_{\theta}(X)= \frac{\theta}{2}=\bar{X}.\]

O valor de \(\theta\) é:

\[\theta=2\bar{X}.\]

Assim o estimador pelo m?todo dos momentos de \(\theta\) é dado por:

\[\widehat{\theta}=T_1=2\bar{X}.\]

Note que:

\[E(\bar{X})= \mu = \frac{\theta}{2}.\]

Assim

\[E(T_1)=E(2\bar{X})=2\;E(\bar{X})=2\;\frac{\theta}{2}=\theta,\] \(T_1\)
é um estimador não viciado de \(\theta\).

Note que:

\[Var(\bar{X})=\frac{ \frac{\theta^2}{12}}{n}=\frac{\theta^2}{12n}.\]

Assim,

\[Var(T_1)=Var(2\bar{X})=4\;Var(\bar{X})=4\;\frac{\theta^2}{12n}=\frac{\theta^2}{3n}.\]

\textbf{Exemplo 2:} Considere
\(X \sim U_d( A),\;\;A=\{1,2,\ldots,\theta\}\)

O espaço paramétrico é dado por:

\[\Theta=\{1,2,\ldots\}.\]

Sabemos que:

\[E_{\theta}(X)=\frac{1+\theta}{2}\;\;\;;\; V(X)=\frac{\theta^2 -1}{12}.\]

Assim,

\[E_{\theta}(X)= \frac{1+\theta}{2}=\bar{X}.\]

O valor de \(\theta\) é:

\[\theta=2\bar{X} -1.\]

Assim o estimador pelo m?todo dos momentos de \(\theta\) é dado por:

\[\widehat{\theta}=T_2=2\bar{X}- 1.\]

Note que:

\[E(\bar{X})=\mu=\frac{1+\theta}{2}.\]

Assim

\[E(T_2)=E(2\bar{X} -1)=2\;E(\bar{X})-1=2\;\frac{1+\theta}{2}-1=\theta,\]

\(T_2\) é um estimador não viciado de \(\theta\).

Note que:

\[Var(\bar{X})=\frac{ \frac{\theta^2 -1}{12}}{n}=\frac{\theta^2 -1}{12n}.\]

Assim

\[Var(T_2)=Var(2\bar{X}-1)=4\;Var(\bar{X})=4\;\frac{\theta^2-1}{12n}=\frac{\theta^2-1}{3n}.\]

\textbf{Exemplo 3:} Seja \(X \sim Normal (\mu, 9).\)

Sabemos que:

\[A=(-\infty,\infty)\;\;;\;\; \Theta= (-\infty,\infty).\]

Além disso:

\[E_{\mu}=\mu\;\;;\;\;V(X)=9.\]

Logo,

\[E_{\mu}=\mu=\bar{X}.\]

Assim

\[\widehat{\mu}=T_3=\bar{X}\]

é o estimador pelo método dos momentos para \(\mu\).

Note que

\[E(T_3)= \mu\;\;\;\;Var(T_3)= \frac{9}{n}.\]

\textbf{Exemplo 4:} Agora considere \(X \sim Exponencial (\lambda).\)

Sabemos que:

\[A=(0,\infty)\;\;;\;\; \Theta= (0,\infty).\]

Além disso:

\[E_{\lambda}=\frac{1}{\lambda}\;\;;\;\;V(X)=\frac{1}{\lambda^2}.\]

O estimador pelo método dos momentos é dado por:

\[E_{\lambda}=\frac{1}{\lambda}=\bar{X}.\]

Logo,

\[\widehat{\lambda}=T_4=\frac{1}{\bar{X}}.\]

Sabemos que

\[S \sim Gama(n,\lambda). \]

Note que:

\[M_S(t)=\left[ \frac{\lambda}{\lambda -t}\right]^n, \;t <\lambda.\]

A função geradora de momentos de \(\bar{X}\) é dada por:

\[M_{\bar{X}}(t)=M_S(t/n)=\left[ \frac{\lambda}{\lambda -t/n}\right]^n, \;t/n <\lambda.\]

\[M_{\bar{X}}(t)=\left[ \frac{n\lambda}{n\lambda -t}\right]^n, \;t < n\lambda.\]

Assim

\[ V= \bar{X} \sim Gama(n,n\lambda).\]

A densidade de \(V\) é dada por:

\[f_V(v)=\frac{(n\lambda)^n}{\Gamma(n)} v^{n-1}\;e^{-n\lambda v}\;\;I_A(v),\;A=(0,\infty).\]

Note que:

\[T_4=\frac{1}{\bar{X}}=\frac{1}{V}.\]

Logo

\[E(T_4)=\displaystyle \int_{0}^{\infty} \;\frac{1}{v}\;\frac{(n\lambda)^n}{\Gamma(n)} v^{n-1}\;e^{-n\lambda v}\;dv \]

\[E(T_4)= \frac{(n\lambda)^n}{\Gamma(n)}\;\displaystyle \int_{0}^{\infty}v^{(n-1)-1}\;e^{-n\lambda v}\;dv.\]

\[E(T_4)= \frac{(n\lambda)^n}{\Gamma(n)}\;IGG(a=n-1,b=n\lambda,c=1) ,\]

com \(a=n-1>0\) ou \(n>1\).

\[E(T_4)= \frac{(n\lambda)^n}{\Gamma(n)}\; \frac{\Gamma(n-1)}{(n\lambda)^{n-1}}= \frac {n\lambda}{n-1}=\frac{n}{n-1}\;\lambda \neq \lambda\]

Logo \(T_4\) é um estimador viciado de \(\lambda\). Mas ele é
assintoticamente não viciado para \(\lambda\).

Vamos calcular a variância de \(T_4\):

\[E(T_4^2)=\displaystyle \int_{0}^{\infty} \;\frac{1}{v^2}\;\frac{(n\lambda)^n}{\Gamma(n)} v^{n-1}\;e^{-n\lambda v}\;dv \]

\[E(T_4^2 )= \frac{(n\lambda)^n}{\Gamma(n)}\;\displaystyle \int_{0}^{\infty}v^{(n-2)-1}\;e^{-n\lambda v}\;dv.\]

\[E(T_4^2)= \frac{(n\lambda)^n}{\Gamma(n)}\;IGG(a=n-2,b=n\lambda,c=1) ,\]

com \(a=n-2>0\) ou \(n>2\).

\[E(T_4^2 )= \frac{(n\lambda)^n}{\Gamma(n)}\; \frac{\Gamma(n-2)}{(n\lambda)^{n-2}}= \frac {n^2 \lambda^2}{(n-1)(n-2)}=\frac{n^2}{(n-1)(n-2)}\;\lambda^2\]

A variância de \(T_4\) ? dada por:

\[Var(T_4)= \frac{n^2}{(n-1)(n-2)}\;\lambda^2- \frac{n^2}{(n-1)^2 }\;\lambda^2\]

\[Var(T_4)= \frac{n^2}{(n-1)^2(n-2)}\;\lambda^2 \]

Note que

\[\displaystyle \lim_{n\to \infty} V(T_4)=0,\]

assim \(T_4\) é um estimador consistente para \(\lambda\).

O próximo exemplo mostrará uma situação distinta das anteriores.

\textbf{Exemplo 5:} Seja
\(Y_i \sim Normal\left(\mu_i=\beta X_i, \sigma^2\right), i=1,2,\ldots,n,\);
independentes com \(X_i,i=1,2,\ldots,n\) constantes conhecidas.

Note que:

\[E(Y_i)=\beta X_i, i=1,2,\ldots,n.\]

Quando as variáveis não são identicamente distribuídas precisamos de uma
definição alternativa para o estimador pelo método dos momentos:

\[\frac{\displaystyle \sum_{i=1}^{n} E(Y_i)}{n}=\bar{Y}.\]

Logo

\[\frac{\displaystyle \sum_{i=1}^{n} \beta X_i}{n}=\bar{Y}.\]

\[ \beta\; \;\frac{\displaystyle \sum_{i=1}^{n} X_i}{n}=\bar{Y}.\]

\[\beta\bar{X}=\bar{Y}.\]

\[\widehat{\beta}=\frac{\bar{Y}}{\bar{X}}= \frac{1}{n\bar{X}}\;\displaystyle \sum_{i=1}^{n} Y_i.\]

O estimador pelo método dos momentos é uma combinação linear de
\(Y_1,Y_2,\ldots,Y_n\).

Vamos mostrar que ele é não viciado.

\[E\left(\widehat{\beta} \right)=\;\frac{1}{n\bar{X}}\;\displaystyle \sum_{i=1}^{n} E(Y_i)=\;\frac{1}{n\bar{X}}\;\displaystyle \sum_{i=1}^{n}\;\beta X_i.\]

\[E\left(\widehat{\beta} \right)=\;\beta\;\;\frac{1}{n\bar{X}}\;\displaystyle \sum_{i=1}^{n}\; X_i=\beta.\]

Vamos calcular agora a variância:

\[Var\left(\widehat{\beta} \right)=\;\frac{1}{n^2\;\bar{X}^2}\;\displaystyle \sum_{i=1}^{n} V(Y_i)=\;\frac{1}{n^2\;\bar{X}^2 }\;n\;\sigma^2=\frac{\sigma^2}{n\;\bar{X}^2 }.\]

\textbf{Exemplo 6} Seja \(X \sim N(0,\sigma^2)\). Qual o estimador \(T\)
pelo método dos momentos para \(\sigma^2\)?

Note que:

\[E(X)=0\;\;E(X^2)= \sigma^2.\]

\[T= \frac{\displaystyle \sum_{i=1}^{n}\; X_i^2}{n}.\]

Note que:

\[E(T)=\sigma^2.\]

\[Var(T)=\frac{1}{n^2} \;\displaystyle \sum_{i=1}^{n}\; V(X_i^2)= \frac{n V(X^2)}{n^2}=\frac{V(X^2)}{n}. \]

Mas

\[Var(X^2)=E(X^4)-E^2(X^2).\]

Sabemos que

\[Z^4=\left[\frac{X-\mu}{\sigma} \right]^4= \frac{X^4}{\sigma^4}.\]

A curtose da normal vale 3 logo:

\[E(Z^4)=3.\]

\[E(X^4)=3 \sigma^4.\]

\[V(X^2)=3 \sigma^4- \sigma^4=2 \sigma^4.\]

Logo,

\[Var(T)= \frac{2 \sigma^4}{n}.\]

Agora vamos estudar o caso biparamétrico:

Seja \(X \sim N(\mu, \sigma^2)\). Calcule os estimadores pelo método dos
momentos para \(\mu\) e \(\sigma^2\).

Como

\[E(X)=\mu\;\;\;\;\text{e}\;\;\;E(X^2)=\sigma^2 +\mu^2.\]

Assim vamos igualar os dois primeiros momentos populacionais aos dois
primeiros momentos amostrais:

\[E(X)=\mu=\bar{X}.\]

\[\widehat{\mu}=\bar{X}.\]

\[E(X^2)=\sigma^2 +\mu^2= \frac{\displaystyle \sum_{i=1}^{n}\; X_i^2}{n}.\]

Logo,

\[\widehat{\sigma^2} +\hat{\mu^2}= \frac{\displaystyle \sum_{i=1}^{n}\; X_i^2}{n}.\]

\[\widehat{\sigma^2}=\frac{\displaystyle \sum_{i=1}^{n}\; X_i^2}{n} -\bar{X}^2 =\frac{\displaystyle \sum_{i=1}^{n}\; X_i^2- n\;\bar{X}^2}{n}\]

\[\widehat{\sigma^2}=\frac{\displaystyle \sum_{i=1}^{n}\; \left(X_i-\bar{X}\right)^2}{n}=\frac{(n-1)S^2}{n}. \]

Note que

\[ E\left(\widehat{\sigma^2}\right)= \frac{n-1}{n} E(S^2)=\frac{n-1}{n}\;\sigma^2,\]

que é viciado mas assintoticamente não viciado.

Por outro lado temos:

\[ Var\left(\widehat{\sigma^2}\right)= \frac{(n-1)^2}{n^2} Var(S^2)=\frac{(n-1)^2}{n^2}\; \frac{2\sigma^4}{n-1}= \frac{2(n-1)}{n^2} \sigma^4.\]

Note que \(\widehat{\sigma^2}\) é um estimador consistente para
\(\sigma^2\).

\textbf{Exemplo 7:} Seja \(X \sim Gama(\alpha >0,\beta >0)\). A f.d.p.
de \(X\) é dada por:

\[f(x|\alpha,\beta)=\frac{\beta^{\alpha}}{\Gamma(\alpha)}\;x^{\alpha-1}\;e^{-\beta\;x}\;I_A(x),\;\;A=(0,\infty).\]

Note que

\[E(X)=\frac{\alpha}{\beta}\;\;\;,V(X)= \frac{\alpha}{\beta^2} \;\;\;\;\;\;;\;E(X^2)=\frac{\alpha}{\beta^2} +\frac{\alpha^2}{\beta^2}.\]

Sejam \(\widehat{\alpha}\) e \(\widehat{\beta}\) os estimadores pelo
método dos momentos:

Assim

\[\frac{\widehat{\alpha}}{\widehat{\beta}}=\bar{X} \]

Assim,

\[\widehat{\alpha}=\bar{X}\;\widehat{\beta}.\]

\[\frac{\widehat{\alpha}}{\widehat{\beta}^2} +\frac{\widehat{\alpha}^2}{\widehat{\beta}^2}=\frac{1}{n}\;\displaystyle \sum_{i=1}^{n}\; X_i^2. \]

Note que:

\[ \frac{\hat{\alpha}}{\widehat{\beta}}\;\frac{1} {\widehat{\beta}} +\frac{\hat{\alpha}^2}{\hat{\beta}^2}=\frac{1}{n}\;\displaystyle \sum_{i=1}^{n}\; X_i^2. \]

\[\bar{X}\;\frac{1} {\widehat{\beta}} +\bar{X}^2=\frac{1}{n}\;\displaystyle \sum_{i=1}^{n}\; X_i^2 \]

\[\bar{X}\;\frac{1} {\hat{\beta}}= \frac{\displaystyle \sum_{i=1}^{n}\; X_i^2 -n \bar{X}^2}{n}= \hat{\sigma^2}\]

logo,

\[\hat{\beta}=\frac{\bar{X}}{ \hat{\sigma^2}}.\]

\[\hat{\alpha}=\bar{X}\;\widehat{\beta}=\frac{\bar{X}^2}{ \widehat{\sigma^2}}.\]

Uma maneira mais rápida de achar este estimadores é notar que:

\[\frac{E(X)}{V(X)}= \beta\]

logo

\[ \hat{\beta}=\frac{\bar{X}}{\widehat{\sigma^2}}.\]

Note que podemos usar tantos os momentos em relação é origem como os
centrais.

\section{Método de Mínimos
Quadrados}\label{muxe9todo-de-muxednimos-quadrados}

Vamos analisar a seção 11.4 do livro do Bussab e Morettin.

Um dos procedimentos mais usados para obter estimadores é aquele que se
baseia no princípio dos mínimos quadrados, introduzido por Gauss em
1794, mas que primeiro apareceu com esse nome no apêndice do tratado de
Legendre, Nouvelles Méthodes pour la Determination des Orbites des
Comètes, publicado em Paris em 1806. Gauss somente viria a publicar seus
resultados em 1809, em Hamburgo. Ambos utilizaram o princípio em conexão
com problemas de Astronomia e Física.

Vejamos o procedimento por meio de um exemplo simples.

**Exemplo* Um engenheiro está estudando a resistência \(Y\) de uma fibra
em função de seu diâmetro \(X\) e notou que as variáveis são
aproximadamente proporcionais, isto é, elas obedecem à relação

\[Y \approx  \theta X,\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; (11.25).\] em que
\(\theta\) é o coeficiente de proporcionalidade. Agora ele deseja
estimar o parâmetro \(\theta\) , baseado numa amostra de cinco unidades,
que, submetidas a mensuração e testes, produziram os resultados:

\begin{longtable}[]{@{}lllllll@{}}
\toprule\noalign{}
& 1 & 2 & 3 & 4 & 5 & Média \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{X} & 1,2 & 1,5 & 1,7 & 2,0 & 2,6 & \(\bar{X}=1,8\) \\
\textbf{Y} & 3,9 & 4,7 & 5,6 & 5,8 & 7,0 & \(\bar{Y}=5,4\) \\
\end{longtable}

Vamos fazer um diagrama de dispersão :

Foi feito um pequeno programa no \textbf{R}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ X}\OtherTok{=}\FunctionTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{17}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{26}\NormalTok{)}\SpecialCharTok{/}\DecValTok{10}\NormalTok{;X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.2 1.5 1.7 2.0 2.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y}\OtherTok{=}\FunctionTok{c}\NormalTok{(}\DecValTok{39}\NormalTok{,}\DecValTok{47}\NormalTok{,}\DecValTok{56}\NormalTok{,}\DecValTok{58}\NormalTok{,}\DecValTok{70}\NormalTok{)}\SpecialCharTok{/}\DecValTok{10}\NormalTok{;Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.9 4.7 5.6 5.8 7.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n}\OtherTok{=}\FunctionTok{length}\NormalTok{(Y);n}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Xb}\OtherTok{=}\FunctionTok{mean}\NormalTok{(X);Xb}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Yb}\OtherTok{=}\FunctionTok{mean}\NormalTok{(Y);Yb}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5.4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(X,Y,}\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{),}\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{8}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a=}\DecValTok{0}\NormalTok{,}\AttributeTok{b=}\DecValTok{3}\NormalTok{,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{unidade3_files/figure-pdf/unnamed-chunk-1-1.pdf}

O valor \(a\) é o coeficiente linear e o valor \(b\) o coeficiente
angular da reta que passa pela origem.

Inspecionando os resultados, conclui-se que \(\hat{\theta}= 3\) parece
ser um valor razoável.

Como verificar a qualidade dessa estimativa? Podemos utilizar o modelo

\[\hat{Y}= 3X\] e ver como esse prevê os valores de \(Y\), para os dados
valores de \(X\), e como são as discrepâncias entre os valores
observados e os estimados pelo modelo.

Essa análise está resumida na Tabela abaixo:

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
X & Y & \(\hat{Y}=3X\) & \(e=Y-\hat{Y}\) & \(e^2\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1,2 & 3,9 & 3,6 & 0,3 & 0,09 \\
1,5 & 4,7 & 4,5 & 0,2 & 0,04 \\
1,7 & 5,6 & 5,1 & 0,5 & 0,25 \\
2,0 & 5,8 & 6,0 & −0,2 & 0,04 \\
2,6 & 7,0 & 7,8 & −0,8 & 0,64 \\
& & \textbf{Total} & \textbf{0} & \textbf{1,06} \\
\end{longtable}

Os valores da coluna \((Y - 3X)=(Y-\bar{Y})\) medem a inadequação do
modelo para cada observação da amostra, enquanto o valor é uma tentativa
de medir o erro quadrático total da amostra?. Como em situações
anteriores, elevou-se ao quadrado para evitar o problema do sinal.

Quanto menor for o erro quadrático total, melhor será a estimativa.

Isso nos sugere procurar a estimativa que torne mínima essa soma de
quadrados. Matematicamente, o problema passa a ser o de encontrar o
valor de \(\theta\) que minimize a função

\[S(\theta)=\displaystyle \sum_{i=1}^{5}\;(Y_i-\theta X_i)^2.\]

O mínimo da função é obtido derivando-a em relação a \(\theta\), e
igualando o resultado a zero (ver Morettin et al., 2005), o que resulta

\[S'(\theta)=2\;\displaystyle \sum_{i=1}^{5}\;(Y_i-\theta X_i)(-X_i),\]

\[S'(\theta)=-2\;\displaystyle \sum_{i=1}^{5}\;(X_i\;Y_i-\theta X_i^2)=0\]

\[S'(\theta)=-2\;\displaystyle \sum_{i=1}^{5}\;X_i\;Y_i+ 2\theta\; \displaystyle \sum_{i=1}^{5} X_i^2.\]

A derivada segunda de \(S\) é dada por:

\[S^{''}(\theta)=2 \displaystyle \sum_{i=1}^{5} X_i^2>0\]

Igualando a derivada primeira a zero temos:

\[ \displaystyle \sum_{i=1}^{5}\;X_i\;Y_i -\theta \displaystyle \sum_{i=1}^{5}\;X_i^2=0\]

Assim

\[\theta=\frac{\displaystyle \sum_{i=1}^{5}\;X_i\;Y_i}{\displaystyle \sum_{i=1}^{5}\;X_i^2},\]

que é ponto de mínimo relativo pois a derivada segunda é sempre
positiva.

O estimador de mínimos quadrados de \(\theta\) é dado por:

\[\hat{\theta}_{MQ}=\frac{\displaystyle \sum_{i=1}^{5}\;X_i\;Y_i}{\displaystyle \sum_{i=1}^{5}\;X_i^2}.\]

Usando os dados acima encontramos \(\hat{\theta}_{MQ} = 2,94\) , que
conduz a um valor mínimo para \(S(\theta)\) de \$ 0,94\$ . Observe que
esse valor é realmente menor do que o observado para \(\theta = 3\), ou
seja, \(1,06\).

Vamos utilizar o \texttt{R} para calcular a estimativa de mínimos
quadrados de \(\theta\) bem como os valores previstos pelo modelo.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X}\OtherTok{=}\FunctionTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{,}\DecValTok{15}\NormalTok{,}\DecValTok{17}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{26}\NormalTok{)}\SpecialCharTok{/}\DecValTok{10}\NormalTok{;X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.2 1.5 1.7 2.0 2.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y}\OtherTok{=}\FunctionTok{c}\NormalTok{(}\DecValTok{39}\NormalTok{,}\DecValTok{47}\NormalTok{,}\DecValTok{56}\NormalTok{,}\DecValTok{58}\NormalTok{,}\DecValTok{70}\NormalTok{)}\SpecialCharTok{/}\DecValTok{10}\NormalTok{;Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.9 4.7 5.6 5.8 7.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n}\OtherTok{=}\FunctionTok{length}\NormalTok{(Y);n}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SX}\OtherTok{=}\FunctionTok{sum}\NormalTok{(X);SX}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X2}\OtherTok{=}\NormalTok{X}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{SX2}\OtherTok{=}\FunctionTok{sum}\NormalTok{(X2);SX2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 17.34
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{XY}\OtherTok{=}\NormalTok{X}\SpecialCharTok{*}\NormalTok{Y}
\NormalTok{SXY}\OtherTok{=}\FunctionTok{sum}\NormalTok{(XY);SXY}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 51.05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{teta\_est}\OtherTok{=}\NormalTok{SXY}\SpecialCharTok{/}\NormalTok{SX2;teta\_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.94406
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(teta\_est,}\DecValTok{2}\NormalTok{)  }\DocumentationTok{\#\#Estimativa de mínimos quadrados.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.94
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y\_est}\OtherTok{=}\NormalTok{teta\_est}\SpecialCharTok{*}\NormalTok{X;Y\_est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 3.532872 4.416090 5.004902 5.888120 7.654556
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e}\OtherTok{=}\NormalTok{Y}\SpecialCharTok{{-}}\NormalTok{Y\_est}
\NormalTok{e2}\OtherTok{=}\NormalTok{e}\SpecialCharTok{\^{}}\DecValTok{2}
\FunctionTok{sum}\NormalTok{(e2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.005738
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tabela}\OtherTok{=}\FunctionTok{cbind}\NormalTok{(X,Y,X2,XY,Y\_est,e,e2);tabela}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       X   Y   X2    XY    Y_est           e          e2
[1,] 1.2 3.9 1.44  4.68 3.532872  0.36712803 0.134782989
[2,] 1.5 4.7 2.25  7.05 4.416090  0.28391003 0.080604908
[3,] 1.7 5.6 2.89  9.52 5.004902  0.59509804 0.354141676
[4,] 2.0 5.8 4.00 11.60 5.888120 -0.08811995 0.007765126
[5,] 2.6 7.0 6.76 18.20 7.654556 -0.65455594 0.428443479
\end{verbatim}

Vamos fazer agora com uma função direta do \texttt{R}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod1}\OtherTok{=}\FunctionTok{lm}\NormalTok{(Y}\SpecialCharTok{\textasciitilde{}}\NormalTok{X }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{);mod1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = Y ~ X - 1)

Coefficients:
    X  
2.944  
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(mod1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       1        2        3        4        5 
3.532872 4.416090 5.004902 5.888120 7.654556 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(mod1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = Y ~ X - 1)

Residuals:
       1        2        3        4        5 
 0.36713  0.28391  0.59510 -0.08812 -0.65456 

Coefficients:
  Estimate Std. Error t value Pr(>|t|)    
X   2.9441     0.1204   24.45 1.66e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.5014 on 4 degrees of freedom
Multiple R-squared:  0.9934,    Adjusted R-squared:  0.9917 
F-statistic: 597.7 on 1 and 4 DF,  p-value: 1.661e-05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(mod1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: Y
          Df  Sum Sq Mean Sq F value    Pr(>F)    
X          1 150.294 150.294  597.75 1.661e-05 ***
Residuals  4   1.006   0.251                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SY2}\OtherTok{=}\FunctionTok{sum}\NormalTok{(Y}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{);SY2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 151.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#Observe que:}
\FloatTok{150.294} \SpecialCharTok{+} \FloatTok{1.006}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 151.3
\end{verbatim}

Como foi dito, não esperávamos uma relação perfeita entre as duas
variáveis, já que o diâmetro da fibra não é o único responsável pela
resistência; outros fatores não controlados afetam o resultado.

Desse modo, duas amostras obtidas do mesmo diâmetro \(X\) não teriam
obrigatoriamente que apresentar o mesmo resultado \(Y\), mas valores em
torno de um valor esperado \(\theta X\).

Em outras palavras, estamos supondo que, para um dado valor da variável
explicativa \$ X\$, os valores da variável resposta \$ Y\$ seguem uma
distribuição de probabilidade \$ f\_Y(y)\$, centrada em \(\theta X\).

Isso equivale a afirmar que, para cada \(X\), o desvio

\[\epsilon  = Y-\theta X\]

segue uma distribuição centrada no zero.

Para melhor entendimento dessa proposição, veja o Capítulo 16. Podemos,
então, escrever

\[E(Y | x) = \theta x, \;\;\mbox{para todo valor}\;\; x.\]

É comum supor que \(\epsilon\) tem a mesma distribuição, para todo valor
\$ x\$ da variável explicativa \(X\).

Desse modo, é comum escrever

\[Y = \theta\;x+ \epsilon,\]

com \(\epsilon\) seguindo a distribuição \(f_{\epsilon}(.)\), com média
zero. Como ilustração, poderíamos supor que

\[\epsilon \sim N(0,\sigma^2),\;\;\;\mbox{para todo}\;\; x.\]

Quanto menor for a variância \(\sigma^2\) , melhor será a previsão de
\(Y\) como função de \$ x\$ . Assim, parece razoável escolher \$
\theta\$ que torna mínima a soma dos quadrados do erros:

O modelo acima pode ser generalizado, de modo a envolver outras funções
do parâmetro, resultando no modelo

\[Y = g(X;  \theta) + \epsilon,\;\;\;\;\;\;\;\;\;\; (11.27)\]

Note que

\[E(Y) = g(X;  \theta),\]

e devemos procurar o valor de \(\theta\) que minimize a função

\[S(\theta)=\displaystyle \sum_{i=1}^{n}\;\epsilon_i^2=\displaystyle \sum_{i=1}^{n}\;(Y_i-E(Y_i))^2=\displaystyle \sum_{i=1}^{n}\;(Y_i- g(X_i;\theta))^2,\;\;\;\;\;\;\;(11.28)\]

Para uma amostra \((X_1, Y_1),\ldots, (X_n, Y_n)\) das variáveis \(X\) e
\(Y\). A solução MQ é chamada de estimador de mínimos quadrados (EMQ) de
\(\theta\).

Nos Capítulos 15 e 16, voltaremos a esse tópico e trataremos com mais
detalhes os chamados modelos lineares.

Suponha que

\[Y_i | X_i = \theta X_i + \epsilon_i, \;\;\;i=1,2,\ldots,n\]

com

\[\epsilon_i \sim N(0,\sigma^2),\;\;\;i=1,2,\ldots,n\]

Na prática usamos:

\[Y_i  = \theta X_i + \epsilon_i, \;\;\;i=1,2,\ldots,n.\]

Aplicando o operador esperança temos:

\[E\left(Y_i \right) = \theta X_i + E(\epsilon_i)= \theta X_i+0= \theta X_i.\]

Calculando a variância temos:

\[Var\left( Y_i \right) = Var\left(\theta X_i + \epsilon_i\right)= Var(\epsilon_i)= \sigma^2.\]

Considere o estimador de MQ de \(\theta\) dado por:

\[\hat{\theta}_{MQ}=\frac{\displaystyle \sum_{i=1}^{n}\;X_i\;Y_i}{\displaystyle \sum_{i=1}^{n}\;X_i^2}= \displaystyle \sum_{i=1}^{n}\;w_i \;Y_i,\]
com

\[w_i= \frac{X_i}{\sum_{i=1}^{n}\;X_i^2}.\]

Inicialmente mostre que:

\[\displaystyle \sum_{i=1}^{n}\;w_i\;X_i =1.\]

\textbf{Prova}

Temos que :

\[\displaystyle \sum_{i=1}^{n}\;w_i\;X_i = \displaystyle \sum_{i=1}^{n}\; \;\frac{X_i}{\sum_{i=1}^{n}\;X_i^2} \times X_i.\]

\[\displaystyle \sum_{i=1}^{n}\;  w_i\;X_i= \frac{1}{\sum_{i=1}^{n}\;X_i^2}\;\;\displaystyle \sum_{i=1}^{n}\;X_i^2=1.\]

Agora mostre que \(\hat{\theta}_{MQ}\) é um estimador não viciado de
\(\theta\).

\[E\left(\hat{\theta}_{MQ}\right)=E\left(\displaystyle \sum_{i=1}^{n}\; w_i Y_i \right),\]

\[E\left(\hat{\theta}_{MQ}\right)=\displaystyle \sum_{i=1}^{n}\;E(w_i\;Y_i)=\displaystyle \sum_{i=1}^{n}\;w_i\;E(\;Y_i)\]

\[E\left(\hat{\theta}_{MQ}\right)= \displaystyle \sum_{i=1}^{n}\;w_i\;\theta\;X_i=\theta\;\displaystyle \sum_{i=1}^{n}\;X_i w_i\]

\[E\left(\hat{\theta}_{MQ}\right)=\theta \times 1=\theta.\]

Agora mostre que:

\[\displaystyle \sum_{i=1}^{n}\;w_i^2\; =\frac{1}{\displaystyle \sum_{i=1}^{n}\;X_i^2}.\]

\textbf{Prova:}

Seja \[A=\displaystyle \sum_{i=1}^{n}\;X_i^2\].

Assim

\[w_i= \frac{X_i}{A}\;\;\;\;\;,w_i^2= \frac{X_i^2}{A^2} \]

\[\displaystyle \sum_{i=1}^{n}\;w_i^2\;=\displaystyle \sum_{i=1}^{n}\;\frac{X_i^2}{A^2}=\frac{1}{A^2}\;\displaystyle \sum_{i=1}^{n}\;X_i^2\]

\[\displaystyle \sum_{i=1}^{n}\;w_i^2\;=\frac{1}{A^2}\;A=\frac{1}{A}=\;\frac{1}{\displaystyle \sum_{i=1}^{n}\;X_i^2}\]

Agora mostre que a variância do estimador de mínimos quadrados de
\(\theta\) é dada por:

\[Var\left(\hat{\theta}_{MQ}\right)= \frac{\sigma^2}{\displaystyle \sum_{i=1}^{n}\;X_i^2}.\]

\textbf{Prova:}

\[Var\left(\hat{\theta}_{MQ}\right)=Var\left(\displaystyle \sum_{i=1}^{n}\; w_i Y_i \right)=\displaystyle \sum_{i=1}^{n}\;Var( w_i Y_i),\]

\[Var\left(\hat{\theta}_{MQ}\right)=\displaystyle \sum_{i=1}^{n}\;w_i^2\;V(Y_i)=\displaystyle \sum_{i=1}^{n}\;w_i^2\;\sigma^2, \]

\[Var\left(\hat{\theta}_{MQ}\right)=\sigma^2\;\displaystyle \sum_{i=1}^{n}\;w_i^2=
\frac{\sigma^2}{\displaystyle \sum_{i=1}^{n}\;X_i^2}.\]

Qual a distribuição Amostral do estimador de mínimos quadrados
\(V=\hat{\theta}_{MQ}\)?

\textbf{Prova:} Sabemos que

\[Y_i \sim N(\theta X_i, \sigma^2)\] e sua função geradora de momentos é
dada por:

\[M_{Y_i}(t)=\exp(\theta X_i\;t + \frac{1}{2} \sigma^2 \;t^2 )\]

A função de momentos de \(V\) é dada por:

\[M_V(t)=E\left(e^{tV}\right)=E\left(e^{t\;\displaystyle \sum_{i=1}^{n}\;w_iY_i }\right)\]

\[M_V(t)=E\left(e^{\;\displaystyle \sum_{i=1}^{n}\;w_i\;t\;Y_i} \right)\]

\[M_V(t)=\displaystyle \prod_{i=1}^{n}\;E\left( e^{wi\;t\;Y_i} \right),\]

\[M_V(t)=\displaystyle \prod_{i=1}^{n}\;M_{Y_i}(w_i t)\]

\[M_V(t)=\displaystyle \prod_{i=1}^{n}\;\exp(\theta X_i\;w_i\;t + \frac{1}{2} \sigma^2 \;w_i^2\;t^2)\]

\[M_V(t)=\exp\left(\theta\;t\; \displaystyle \sum_{i=1}^{n}X_i\;w_i\; + \frac{1}{2} \sigma^2 \;\displaystyle \sum_{i=1}^{n} w_i^2\;t^2\right)\]

\[M_V(t)=\exp\left(\theta\;t\;\times 1 +\frac{1}{2}\times  \sigma^2  \times \frac{1}{\displaystyle \sum_{i=1}^{n} X_i^2}\;t^2\right)\]

\[M_V(t)=\exp\left(\theta\;t\; +\frac{1}{2}   \times \frac{\sigma^2}{\displaystyle \sum_{i=1}^{n} X_i^2}\;t^2\right)\]

Assim

\[V=\hat{\theta}_{MQ}  \sim N \left( \theta,\frac {\sigma^2}{\displaystyle \sum_{i=1}^{n} X_i^2}\right)\]

Qual o estimador de mínimos quadrados baseado em uma amostra aleatória
de tamanho \(n\), \(X_1,X_2,\ldots,X_n)\), de uma variável \(X\) com
distribuição:

\begin{itemize}
\tightlist
\item
  \(X \sim Poisson(\theta)\).
\item
  \(X \sim N(\mu,1)\).
\item
  \(X \sim Ber(p).\)
\end{itemize}

\textbf{Solução:} Devemos minimizar

\begin{verbatim}
Sabemos que
\end{verbatim}

\[E(X_i)=\theta,\;\;i=1,2,\ldots,n.\]

\[S(\theta)=\displaystyle \sum_{i=1}^{n}\;(X_i-E(X_i))^2=\displaystyle \sum_{i=1}^{n}\;(X_i-\theta)^2\]

\[S(\theta)=\displaystyle \sum_{i=1}^{n}\;X_i^2- 2\displaystyle \sum_{i=1}^{n}\;X_i\;\theta + n\theta^2=a\theta^2 +b \theta +c\]

Como \(a>0\) temos

\[\theta_{min}=\frac{-b}{2a}=\frac{2\displaystyle \sum_{i=1}^{n}\;X_i}{2n}=\bar{X}\]

que é o nosso estimador de mínimos quadrados.

No caso da normal temos:

Sabemos que

\[E(X_i)=\mu,\;\;i=1,2,\ldots,n.\]

\[S(\mu)=\displaystyle \sum_{i=1}^{n}\;(X_i-E(X_i))^2=\displaystyle \sum_{i=1}^{n}\;(X_i-\mu)^2\]

\[\mu_{min}=\bar{X},\]

que é o nosso estimador de mínimos quadrados.

No caso da Bernouli temos

\[E(X_i)=p,\;\;i=1,2,\ldots,n.\]

\[S(p)=\displaystyle \sum_{i=1}^{n}\;(X_i-E(X_i))^2=\displaystyle \sum_{i=1}^{n}\;(X_i-p)^2\]

\[S(p)=np^2 -2\displaystyle \sum_{i=1}^{n}\;X_i\;p  +\displaystyle \sum_{i=1}^{n}\;X_i^2\]

\[S'(p)=2pn-2\displaystyle \sum_{i=1}^{n}\;X_i \]

\[S^{''}(p)=2n >0\]

De \(S'(p)=0\) temos

\[p_{min}=\bar{X},\]

que é o nosso estimador de mínimos quadrados.

\textbf{Problemas}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estamos estudando o modelo \(y_t= \mu  + \epsilon_t\), para o qual uma
  amostra de cinco elementos produziu os seguintes valores para
  \(y_t: 3,
  5, 6, 8, 16.\)
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Calcule os valores de \[S(\mu)=\displaystyle  \sum_{t} \;(y_t-\mu)^2\]
  para \(\mu = 6, 7, 8, 9, 10\), e faça o gráfico de \(S(\mu)\) em
  relação a \(\mu\).
\end{enumerate}

Qual o valor que parece tornar mínimo \(S(\mu)\)?

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Derivando \(S(\mu)\) em relação a \(\mu\) , e igualando o resultado a
  zero, você encontrará o EMQ de \(\mu\). Usando os dados acima,
  encontre a estimativa para \(\mu\) e compare com o resultado do item
  anterior.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Os dados abaixo referem-se ao índice de inflação (\(y_t\)) de 1967 a
  1979.
\end{enumerate}

\begin{longtable}[]{@{}llllllll@{}}
\toprule\noalign{}
Ano (\(t\)) & 1967 & 1969 & 1971 & 1973 & 1975 & 1977 & 1979 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Inflação (\(y_t\)) & 128 & 192 & 277 & 373 & 613 & 1236 & 2639 \\
\end{longtable}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  Faça o gráfico de \(y_t\) contra \(t\).
\item
  Considere ajustar o modelo
\end{enumerate}

\[y_t= \alpha + \beta t + \epsilon_t \]

aos dados. Encontre as estimativas de mínimos quadrados de \(\alpha\) e
\(\beta\).

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{2}
\item
  Qual seria a inflação em 1981?
\item
  Você teria alguma restrição em adotar o modelo linear nesse caso ?
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  No Problema 7, determinamos os estimadores de mínimos quadrados para o
  modelo \[y_t= f(t) + \epsilon_t,\] no qual
\end{enumerate}

\[f(t) = \alpha + \beta\;t\].

Suponha agora que

\[f(t) = \alpha + \beta\; x_t,\; t = 1,2,\ldots, n,\]

ou seja, temos \(n\) valores fixos \(x_1,x_2,\ldots,x_n\) uma variável
fixa (não aleatória) \(x\). Obtenha os EMQ de \(\alpha\) e \(\beta\)
para esse modelo.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Aplique os resultados do Problema 3 para os dados a seguir:
\end{enumerate}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1389}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0833}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1111}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\(t\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
6
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
7
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
8
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
9
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
10
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(x_t\) & 1,5 & 1,8 & 1,6 & 2,5 & 4,0 & 3,8 & 4,5 & 5,1 & 6,5 & 6,0 \\
\(y_t\) & 66,8 & 67,0 & 66,9 & 67,6 & 68,9 & 68,7 & 69,3 & 69,8 & 71,0 &
70,6 \\
\end{longtable}

\bookmarksetup{startatroot}

\chapter{Estimação Intervalar}\label{estimauxe7uxe3o-intervalar}

\bookmarksetup{startatroot}

\chapter{Testes de Hipóteses}\label{testes-de-hipuxf3teses}

\bookmarksetup{startatroot}

\chapter{Testes de Homogeneidade e
Independência}\label{testes-de-homogeneidade-e-independuxeancia}

\bookmarksetup{startatroot}

\chapter{Inferência Estatística e Ciência de
Dados}\label{inferuxeancia-estatuxedstica-e-ciuxeancia-de-dados}

\bookmarksetup{startatroot}

\chapter*{Referências}\label{referuxeancias}
\addcontentsline{toc}{chapter}{Referências}

\markboth{Referências}{Referências}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\end{CSLReferences}



\end{document}
